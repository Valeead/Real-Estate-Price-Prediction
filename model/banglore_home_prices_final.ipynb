{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34301e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e183bd9",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18abd474",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Bengaluru_House_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d3d31cb3180b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Bengaluru_House_Data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Bengaluru_House_Data.csv'"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"Bengaluru_House_Data.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('area_type')['area_type'].agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f623c",
   "metadata": {},
   "source": [
    "**Drop features that are not required to build our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(['area_type','availability','society','balcony'],axis = 1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd127342",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna()\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37817a1b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07310bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c5a78",
   "metadata": {},
   "source": [
    "**Add new feature for bhk (Bedrooms Hall Kitchen)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670bb0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['bhk'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caffe135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3[df3.bhk>20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19bda5",
   "metadata": {},
   "source": [
    "**Explore total_sqft feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72118c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['total_sqft'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf57dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[~df3['total_sqft'].apply(is_float)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fbaf0",
   "metadata": {},
   "source": [
    "**Above shows that total_sqft can be a range (e.g. 2100-2850). For such case we can just take average of min and max value in the range. There are other cases such as 34.46Sq. Meter which one can convert to square ft using unit conversion. I am going to just drop such corner cases to keep things simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cbd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_sqft_to_num('2166')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf74352",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_sqft_to_num('1015 - 1540')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_sqft_to_num('34.46Sq. Meter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25a2b8",
   "metadata": {},
   "source": [
    "**For below row, it shows total_sqft as 2475 which is an average of the range 2100-2850**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ed98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "df4['total_sqft'] = df4['total_sqft'].apply(convert_sqft_to_num)\n",
    "df4.loc[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada35ff",
   "metadata": {},
   "source": [
    "**Add new feature called price per square feet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efa204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0ebb9",
   "metadata": {},
   "source": [
    "**Examine locations which is a categorical variable. We need to apply dimensionality reduction technique here to reduce number of locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f862cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.location = df5.location.apply(lambda x: x.strip())\n",
    "location_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_stats[location_stats<=10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ccb94",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a87af",
   "metadata": {},
   "source": [
    "**Any location having less than 10 data points should be tagged as \"other\" location. This way number of categories can be reduced by huge amount. Later on when we do one hot encoding, it will help us with having fewer dummy columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "locations_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe62398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.location = df5.location.apply(lambda x: 'other' if x in locations_stats_less_than_10 else x)\n",
    "len(df5.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4adf69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c261397",
   "metadata": {},
   "source": [
    "# Outlier Removal Using Business Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e20188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[df5.total_sqft/df5.bhk<300].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2451aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5[~(df5.total_sqft/df5.bhk<300)]\n",
    "df6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342c8bb",
   "metadata": {},
   "source": [
    "# Outlier Removal Using Standard Deviation and Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b37034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.price_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba24450",
   "metadata": {},
   "source": [
    "**Here we find that min price per sqft is 267 rs/sqft whereas max is 12000000, this shows a wide variation in property prices. We should remove outliers per location using mean and one standard deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df7 = remove_pps_outliers(df6)\n",
    "df7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed92591",
   "metadata": {},
   "source": [
    "**Let's check if for a given location how does the 2 BHK and 3 BHK property prices look like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689facb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_chart(df,location):\n",
    "    bhk2 = df[(df.location==location) & (df.bhk==2)]\n",
    "    bhk3 = df[(df.location==location) & (df.bhk==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "    \n",
    "plot_scatter_chart(df7,\"Hebbal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1be4b",
   "metadata": {},
   "source": [
    "**We should also remove properties where for same location, the price of (for example) 3 bedroom apartment is less than 2 bedroom apartment (with same square ft area). What we will do is for a given location, we will build a dictionary of stats per bhk, i.e.**\n",
    "\n",
    "{\n",
    "    '1' : {\n",
    "        'mean': 4000,\n",
    "        'std: 2000,\n",
    "        'count': 34\n",
    "    },\n",
    "    '2' : {\n",
    "        'mean': 4300,\n",
    "        'std: 2300,\n",
    "        'count': 22\n",
    "    },    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c6a6e",
   "metadata": {},
   "source": [
    "**Now we can remove those 2 BHK apartments whose price_per_sqft is less than mean price_per_sqft of 1 BHK apartment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "    return df.drop(exclude_indices,axis='index')\n",
    "df8 = remove_bhk_outliers(df7)\n",
    "# df8 = df7.copy()\n",
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_chart(df8,\"Hebbal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccf1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(df8.price_per_sqft,rwidth=0.8)\n",
    "plt.xlabel(\"Price Per Square Feet\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e8bc0",
   "metadata": {},
   "source": [
    "# Outlier Removal Using Bathrooms Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c632fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8[df8.bath>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df8.bath,rwidth=0.8)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8[df8.bath>df8.bhk+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c2621",
   "metadata": {},
   "source": [
    "**It is unusual to have 2 more bathrooms than number of bedrooms in a home**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced56ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df8[df8.bath<df8.bhk+2]\n",
    "df9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df9.drop(['size','price_per_sqft'],axis=1)\n",
    "df10.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe16f4",
   "metadata": {},
   "source": [
    "# Use One Hot Encoding For Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df10.location)\n",
    "dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.concat([df10,dummies.drop('other',axis = 1)],axis = 1)\n",
    "df11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa712e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df12 = df11.drop('location',axis = 1)\n",
    "df12.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf26ef",
   "metadata": {},
   "source": [
    "# Building a Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df12.drop('price',axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df12.price\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5757dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf694d",
   "metadata": {},
   "source": [
    "## Use K Fold cross validation to measure accuracy of our LinearRegression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d9a96",
   "metadata": {},
   "source": [
    "**We can see that in 5 iterations we get a score above 80% all the time. This is pretty good but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV for this purpose**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fe1cc",
   "metadata": {},
   "source": [
    "## Find best model using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos = {\n",
    "        'linear_regression' : {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82ce62",
   "metadata": {},
   "source": [
    "**Based on above results we can say that LinearRegression gives the best score. Hence we will use that.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab13607",
   "metadata": {},
   "source": [
    "## Test the model for few properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(location,sqft,bath,bhk):    \n",
    "    loc_index = np.where(X.columns==location)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr_clf.predict([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a08f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('1st Phase JP Nagar',1000, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d69c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('1st Phase JP Nagar',1000, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Indira Nagar',1000, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf106509",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Indira Nagar',1000, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ded3c",
   "metadata": {},
   "source": [
    "### Export the tested model to a pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('banglore_home_prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lr_clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f4325",
   "metadata": {},
   "source": [
    "### Export location and column information to a file that will be useful later on in our prediction application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a81f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed211303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
